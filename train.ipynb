{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import math\n",
    "from torch.autograd import Function\n",
    "import numpy as np\n",
    "import os\n",
    "from torchvision import datasets as datasets\n",
    "from torchvision import transforms as transforms\n",
    "from torch.utils.data import DataLoader as DataLoader\n",
    "\n",
    "from models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BNN():\n",
    "    def create_dataloader(self, name, train_batch, test_batch):\n",
    "        path = \"~/binarized-neural-network/\"\n",
    "\n",
    "        if name == \"MNIST\":\n",
    "            directory = path + \"mnist/\"\n",
    "\n",
    "            train = datasets.MNIST(root=directory, train=True, download=True, \n",
    "                                   transform=transforms.Compose([transforms.ToTensor(), \n",
    "                                                                 transforms.Normalize((0.1307,), (0.3081,))]))\n",
    "\n",
    "            test = datasets.MNIST(root=directory, train=False,\n",
    "                                  transform=transforms.Compose([transforms.ToTensor(),\n",
    "                                                                  transforms.Normalize((0.1307,), (0.3081,))]))\n",
    "\n",
    "            train_loader = DataLoader(train, batch_size=train_batch, \n",
    "                                      shuffle=True, pin_memory=True, num_workers=1)\n",
    "            test_loader = DataLoader(test, batch_size=test_batch,\n",
    "                                     shuffle=True, pin_memory=True, num_workers=1)\n",
    "\n",
    "        return train, test, train_loader, test_loader\n",
    "    \n",
    "    def create_model(self, name):\n",
    "        if name == \"MNIST\":\n",
    "            net = MNIST_BNN().to(self.device)\n",
    "        \n",
    "        return net\n",
    "\n",
    "    def __init__(self, name, output_dir, train_batch=100, test_batch=100, num_epochs=10, lr=1e-3):\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        \n",
    "        self.train_set, self.test_set, self.train_loader, self.test_loader = self.create_dataloader(name, \n",
    "                                                                                                    train_batch, \n",
    "                                                                                                    test_batch)\n",
    "        self.net = self.create_model(name)\n",
    "        \n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.optimizer = optim.Adam(self.net.parameters(), lr=lr)\n",
    "        \n",
    "        self.epochs = num_epochs\n",
    "        self.train_batch = train_batch\n",
    "        self.test_batch = test_batch\n",
    "        self.num_epochs = num_epochs\n",
    "        self.lr = lr\n",
    "        \n",
    "        self.history = []\n",
    "        self.train_loss = []\n",
    "        self.train_acc = []\n",
    "        self.test_loss = []\n",
    "        self.test_acc = []\n",
    "        \n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        self.checkpoint_path = os.path.join(output_dir, \n",
    "                                       \"checkpoint.pth.tar\")\n",
    "        self.config_path = os.path.join(output_dir, \"config.txt\")\n",
    "        \n",
    "        # Transfer all local arguments/variables into attributes\n",
    "        locs = {k: v for k, v in locals().items() if k is not 'self'}\n",
    "        self.__dict__.update(locs)\n",
    "        \n",
    "        if os.path.isfile(self.config_path):\n",
    "            with open(self.config_path, 'r') as f:\n",
    "                if f.read()[:-1] != repr(self):\n",
    "                    raise ValueError(\n",
    "                        \"Cannot create this experiment: \"\n",
    "                        \"I found a checkpoint conflicting with the current setting.\")\n",
    "            self.load()\n",
    "        else:\n",
    "            self.save()\n",
    "            \n",
    "    @property\n",
    "    def epoch(self):\n",
    "        return len(self.history)\n",
    "    \n",
    "    def setting(self):\n",
    "        return {'Model': self.net,\n",
    "                'Optimizer': self.optimizer,\n",
    "                'TrainSet' : self.train_set,\n",
    "                'TestSet' : self.test_set,\n",
    "                'TrainBatch': self.train_batch,\n",
    "                'TestBatch' : self.test_batch}\n",
    "    \n",
    "    def __repr__(self):\n",
    "        string = ''\n",
    "        for key, val in self.setting().items():\n",
    "            string += '{}({})\\n'.format(key, val)\n",
    "        return string\n",
    "    \n",
    "    def state_dict(self):\n",
    "        \"\"\"Returns the current state of the experiment.\"\"\"\n",
    "        return {'Model': self.net.state_dict(),\n",
    "                'Optimizer': self.optimizer.state_dict(),\n",
    "                'History': self.history,\n",
    "                'TrainLoss' : self.train_loss,\n",
    "                'TrainAcc' : self.train_acc,\n",
    "                'TestLoss' : self.test_loss,\n",
    "                'TestAcc' : self.test_acc}\n",
    "    \n",
    "    def load_state_dict(self, checkpoint):\n",
    "        # load from pickled checkpoint\n",
    "        self.net.load_state_dict(checkpoint['Model'])\n",
    "        self.optimizer.load_state_dict(checkpoint['Optimizer'])\n",
    "        self.history = checkpoint['History']\n",
    "        self.train_loss = checkpoint['TrainLoss']\n",
    "        self.train_acc = checkpoint['TrainAcc']\n",
    "        self.test_loss = checkpoint['TestLoss']\n",
    "        self.test_acc = checkpoint['TestAcc']\n",
    "        \n",
    "        for state in self.optimizer.state.values():\n",
    "            for k, v in state.items():\n",
    "                if isinstance(v, torch.Tensor):\n",
    "                    state[k] = v.to(self.device)\n",
    "    def save(self):\n",
    "        ''''Saves the experiment on disk, i.e, create/update the last checkpoint.'''        \n",
    "        torch.save(self.state_dict(), self.checkpoint_path)\n",
    "        with open(self.config_path, 'w') as f:\n",
    "            print(self, file=f)  \n",
    "    \n",
    "    def load(self):\n",
    "        \"\"\"Loads the experiment from the last checkpoint saved on disk.\"\"\"\n",
    "        checkpoint = torch.load(self.checkpoint_path,\n",
    "                                map_location=self.device)\n",
    "        self.load_state_dict(checkpoint)\n",
    "        del checkpoint\n",
    "    \n",
    "    def evaluate(self):\n",
    "        self.net.eval()\n",
    "        \n",
    "        loss, correct = 0.0, 0.0\n",
    "\n",
    "        for data, target in self.test_loader:\n",
    "            if self.device == 'cuda':\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "\n",
    "            data, target = Variable(data), Variable(target)\n",
    "\n",
    "            output = self.net(data)\n",
    "\n",
    "            loss += self.criterion(output, target).item()\n",
    "\n",
    "            pred = torch.max(output, dim=1)[1]\n",
    "\n",
    "            correct += (pred == target).sum()\n",
    "\n",
    "        loss = float(loss) / len(self.test_loader.dataset)\n",
    "        acc = float(correct) / len(self.test_loader.dataset)\n",
    "        \n",
    "        return loss, acc\n",
    "    \n",
    "    def train(self):\n",
    "        self.net.train()\n",
    "        \n",
    "        start_epoch = self.epoch\n",
    "        print(\"Start/Continue training from epoch {}\".format(start_epoch))\n",
    "        \n",
    "        for epoch in range(start_epoch, self.epochs):\n",
    "            \n",
    "            running_loss, running_acc = 0.0, 0.0\n",
    "            \n",
    "            for idx, (data, target) in enumerate(self.train_loader):\n",
    "                if self.device == 'cuda':\n",
    "                    data, target = data.cuda(), target.cuda()\n",
    "                data, target = Variable(data), Variable(target)\n",
    "\n",
    "                self.optimizer.zero_grad()\n",
    "                output = self.net(data)\n",
    "                loss = self.criterion(output, target)\n",
    "\n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "\n",
    "                for p in list(self.net.parameters()):\n",
    "                    if hasattr(p, 'full_precision'):\n",
    "                        p.data.copy_(p.full_precision)\n",
    "\n",
    "                self.optimizer.step()\n",
    "\n",
    "                for p in list(self.net.parameters()):\n",
    "                    if hasattr(p, 'full_precision'):\n",
    "                        p.full_precision.copy_(p.data.clamp_(-1,1))\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    running_loss += loss.item()\n",
    "                    pred = torch.max(output, dim=1)[1]\n",
    "                    running_acc += (pred == target).sum()\n",
    "                                        \n",
    "                    if idx % 63 == 0:\n",
    "                        print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                            epoch, idx * len(data), len(self.train_loader.dataset),\n",
    "                            100. * idx / len(self.train_loader), loss.item()))\n",
    "                        \n",
    "                torch.cuda.empty_cache()\n",
    "        \n",
    "            train_loss = float(running_loss) / len(self.train_loader.dataset)\n",
    "            train_acc = float(running_acc) / len(self.train_loader.dataset)\n",
    "            test_loss, test_acc = self.evaluate()\n",
    "\n",
    "            print('\\nTrain set: Average Loss: {:.4f}, Accuracy: {:.0f}%'.format(train_loss, 100. * train_acc))\n",
    "            print('Test set: Average Loss: {:.4f}, Accuracy: {:.0f}%\\n'.format(test_loss, 100. * test_acc))\n",
    "            \n",
    "            self.history.append(epoch)\n",
    "            self.train_loss.append(train_loss)\n",
    "            self.train_acc.append(train_acc)\n",
    "            self.test_loss.append(test_loss)\n",
    "            self.test_acc.append(test_acc)\n",
    "            \n",
    "            self.save()\n",
    "            \n",
    "        print(\"Finish training for {} epochs\".format(self.epochs))       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start/Continue training from epoch 10\n",
      "Finish training for 10 epochs\n"
     ]
    }
   ],
   "source": [
    "bnn = BNN(name=\"MNIST\", output_dir=\"mnist_logs/\")\n",
    "bnn.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FC1 weights (min, max): -1.0 1.0\n",
      "FC2 weights (min, max): -1.0 1.0\n",
      "FC3 weights (min, max): -1.0 1.0\n",
      "FC4 weights (min, max): -1.0 1.0\n",
      "FC1 bias (min, max): -1.0 1.0\n",
      "FC2 bias (min, max): -1.0 1.0\n",
      "FC3 bias (min, max): -1.0 1.0\n",
      "FC4 bias (min, max): -1.0 1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"FC1 weights (min, max):\", torch.min(bnn.net.fc1.weight).item(), torch.max(bnn.net.fc1.weight).item())\n",
    "print(\"FC2 weights (min, max):\", torch.min(bnn.net.fc2.weight).item(), torch.max(bnn.net.fc2.weight).item())\n",
    "print(\"FC3 weights (min, max):\", torch.min(bnn.net.fc3.weight).item(), torch.max(bnn.net.fc3.weight).item())\n",
    "print(\"FC4 weights (min, max):\", torch.min(bnn.net.fc4.weight).item(), torch.max(bnn.net.fc4.weight).item())\n",
    "\n",
    "print(\"FC1 bias (min, max):\", torch.min(bnn.net.fc1.bias).item(), torch.max(bnn.net.fc1.bias).item())\n",
    "print(\"FC2 bias (min, max):\", torch.min(bnn.net.fc2.bias).item(), torch.max(bnn.net.fc2.bias).item())\n",
    "print(\"FC3 bias (min, max):\", torch.min(bnn.net.fc3.bias).item(), torch.max(bnn.net.fc3.bias).item())\n",
    "print(\"FC4 bias (min, max):\", torch.min(bnn.net.fc4.bias).item(), torch.max(bnn.net.fc4.bias).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear = []\n",
    "bn = []\n",
    "\n",
    "for name, module in list(bnn.net._modules.items()):\n",
    "    if 'bn' in name:\n",
    "        scale = torch.cuda.FloatTensor(module.weight).unsqueeze(dim=1)\n",
    "        bias = torch.cuda.FloatTensor(module.bias).unsqueeze(dim=1)\n",
    "        mean = torch.cuda.FloatTensor(module.running_mean).unsqueeze(dim=1)\n",
    "        std = torch.cuda.FloatTensor(module.running_var ** 0.5).unsqueeze(dim=1)\n",
    "        \n",
    "        bn.append((scale, bias, mean, std))\n",
    "        \n",
    "    if 'fc' in name:\n",
    "        linear.append(module)\n",
    "\n",
    "def manual_prop(manual):\n",
    "    layer1 = torch.matmul(linear[0].weight, manual) + linear[0].bias.unsqueeze(1)\n",
    "    layer1 = bn[0][0] * ((layer1 - bn[0][2]) / bn[0][3]) + bn[0][1]\n",
    "    layer1 = binarize(layer1)\n",
    "        \n",
    "    layer2 = torch.matmul(linear[1].weight, layer1) + linear[1].bias.unsqueeze(1)\n",
    "    layer2 = bn[1][0] * ((layer2 - bn[1][2]) / bn[1][3]) + bn[1][1]\n",
    "    layer2 = binarize(layer2)\n",
    "\n",
    "    layer3 = torch.matmul(linear[2].weight, layer2) + linear[2].bias.unsqueeze(1)\n",
    "    layer3 = bn[2][0] * ((layer3 - bn[2][2]) / bn[2][3]) + bn[2][1]\n",
    "    layer3 = binarize(layer3)\n",
    "\n",
    "    layer4 = torch.matmul(linear[3].weight, layer3) + linear[3].bias.unsqueeze(1)\n",
    "\n",
    "    return layer4.squeeze(2).argmax(dim=1).cpu()\n",
    "\n",
    "def acc(loader):\n",
    "    total = 0\n",
    "\n",
    "    for (data, target) in loader:\n",
    "        data = data.cuda()\n",
    "\n",
    "        manual = data.view(loader.batch_size, -1, 1)\n",
    "        manual = binarize(manual)\n",
    "        manual_out = manual_prop(manual)\n",
    "        \n",
    "        total += (manual_out == target).sum().item()\n",
    "\n",
    "    print(total / len(loader.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc(bnn.test_loader)\n",
    "\n",
    "print(\"Train acc of normal prop:\", bnn.train_acc[-1])\n",
    "print(\"Test acc of normal prop:\", bnn.test_acc[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
